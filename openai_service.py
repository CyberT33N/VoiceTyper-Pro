import os
import sys
import asyncio
import re # Import re for regex substitutions
from openai import OpenAI
from llm_prompts import (
    STANDARD_BASE_PROMPT, 
    LLM_OPTIMIZED_BASE_PROMPT,
    EN_STANDARD_ADDITIONS,
    EN_LLM_OPTIMIZED_ADDITIONS,
    DE_STANDARD_ADDITIONS,
    DE_LLM_OPTIMIZED_ADDITIONS,
    FR_STANDARD_ADDITIONS,
    FR_LLM_OPTIMIZED_ADDITIONS,
    ES_STANDARD_ADDITIONS,
    ES_LLM_OPTIMIZED_ADDITIONS,
    GENERIC_STANDARD_ADDITIONS,
    GENERIC_LLM_OPTIMIZED_ADDITIONS
)

class OpenAIService:
    """OpenAI implementation of speech-to-text service"""
    
    def __init__(self, client, use_post_processing=False, llm_optimized=False):
        self.client = client
        self.use_post_processing = use_post_processing
        self.llm_optimized = llm_optimized
        
        # Neuer Debug-Log: Zeige deutlich die Initialisierungsparameter an
        print(f"üîßüîßüîß OpenAIService initialisiert mit: use_post_processing={self.use_post_processing}, llm_optimized={self.llm_optimized}", file=sys.stderr)
        
        # If llm_optimized is True, post_processing must also be True
        if self.llm_optimized and not self.use_post_processing:
            self.use_post_processing = True
            print("‚ö†Ô∏è Note: LLM optimization requires post-processing. Enabling post-processing automatically.", file=sys.stderr)
        
        # Define German word replacements as a class attribute
        self.german_word_replacements = {
            "v-test": "Vitest",
            "v-tests": "Vitest",
            "package jason": "package.json",
            "achse": ".exe",
            "echse": ".exe",
            "gyra": "Jira",
            "effektor": "Refactor",
            "pulverquest": "Pull Request",
            "konsole locks": "console.log",
            "juju-id": "UUID",
            "loks": "Logs",
            "locken": "loggen",
            "commentline": "Command Line"
        }
    
    @classmethod
    def initialize(cls, api_key, use_post_processing=False, llm_optimized=False):
        """Initialize OpenAI client with API key"""
        try:
            client = OpenAI(api_key=api_key)
            return cls(client, use_post_processing, llm_optimized)
        except Exception as e:
            print(f"OpenAI init error: {str(e)}", file=sys.stderr)
            raise Exception(f"Failed to initialize OpenAI: {str(e)}")
    
    async def transcribe_audio(self, audio_file, language=None):
        """Transcribe audio file using OpenAI"""
        try:
            # Debug-Log f√ºr aktuelle Werte der Parameter
            print(f"üéØ transcribe_audio Start mit: use_post_processing={self.use_post_processing}, llm_optimized={self.llm_optimized}", file=sys.stderr)
            
            with open(audio_file, 'rb') as audio:
                # Use asyncio to run the synchronous API call in a thread pool
                loop = asyncio.get_event_loop()
                
                # Prepare parameters for the API call
                params = {
                    "model": "whisper-1",
                    "file": audio,
                }
                
                # OpenAI doesn't support 'auto' - we just omit the language parameter
                # for auto-detection. For other languages, ensure we're sending valid codes
                if language and language != "auto":
                    # Make sure we're using a valid ISO-639-1 code
                    params["language"] = language
                
                print(f"üé§ Calling OpenAI Whisper with params: {params}", file=sys.stderr)
                
                transcription = await loop.run_in_executor(
                    None,
                    lambda: self.client.audio.transcriptions.create(**params)
                )
                
                transcript = transcription.text
                # Log the full initial transcript
                print(f"üìù Initial transcription: '{transcript}'", file=sys.stderr)
                
                # Apply post-processing if enabled
                if self.use_post_processing and transcript:
                    print(f"‚è≥ Applying GPT-4 post-processing to improve quality... (language={language})", file=sys.stderr)
                    print(f"üìä DEBUG: Post-processing is enabled = {self.use_post_processing}", file=sys.stderr)
                    if self.llm_optimized:
                        print(f"üöÄ LLM optimization is enabled. Text will be optimized for LLM consumption.", file=sys.stderr)
                    processed_transcript = await self.post_process_with_gpt4(transcript, language)
                    print(f"üèÅ FINAL RESULT: '{processed_transcript}'", file=sys.stderr)
                    return processed_transcript
                else:
                    print(f"‚ö†Ô∏è No post-processing applied! use_post_processing={self.use_post_processing}", file=sys.stderr)
                
                return transcript
        except Exception as e:
            print(f"‚ùå OpenAI transcription error: {str(e)}", file=sys.stderr)
            raise Exception(f"OpenAI transcription error: {str(e)}")
    
    async def post_process_with_gpt4(self, transcript, language=None):
        """Post-process transcript with GPT-4 to improve quality"""
        try:
            loop = asyncio.get_event_loop()
            
            # Log language parameter
            print(f"üö© DEBUG: post_process_with_gpt4 called with language='{language}'", file=sys.stderr)
            print(f"üîß Settings: post_processing={self.use_post_processing}, llm_optimized={self.llm_optimized}", file=sys.stderr)
            
            # Create a system prompt based on language and optimization mode
            system_prompt = self._get_system_prompt_for_language(language)
            
            print(f"üß† Starting GPT-4 post-processing for transcript...", file=sys.stderr)
            if self.llm_optimized:
                print(f"üìã LLM-Optimization: Aktiviert - Text wird mit Markdown und f√ºr LLMs optimiert", file=sys.stderr)
                print(f"‚ÑπÔ∏è LLM-Optimierung wird Formatierung, Struktur und Lesbarkeit f√ºr LLMs verbessern", file=sys.stderr)
                print(f"üîç LLM-Interaktionserkennung: Aktiviert - Direkte Anfragen werden erkannt und verarbeitet", file=sys.stderr)
            print(f"Original transcript: '{transcript}'", file=sys.stderr)
            
            # Pr√ºfen, ob der Transcript eine direkte LLM-Anfrage enth√§lt (f√ºr Logs)
            if self.llm_optimized and re.search(r"(hey|hallo|hi)\s+llm", transcript, re.IGNORECASE):
                print(f"üëã Direkte LLM-Anfrage erkannt: Wird speziell verarbeitet", file=sys.stderr)
            
            response = await loop.run_in_executor(
                None,
                lambda: self.client.chat.completions.create(
                    model="gpt-4o",
                    temperature=0,
                    messages=[
                        {
                            "role": "system",
                            "content": system_prompt
                        },
                        {
                            "role": "user",
                            "content": transcript
                        }
                    ]
                )
            )
            
            processed_text = response.choices[0].message.content
            print(f"‚úÖ GPT-4 post-processing complete", file=sys.stderr)
            print(f"üß† Text after GPT-4: '{processed_text}'", file=sys.stderr)
            
            # Pr√ºfen, ob die Antwort eine Trennung enth√§lt (f√ºr Logs)
            if self.llm_optimized and "---" in processed_text:
                print(f"üîÄ Antwort enth√§lt Trennung zwischen Original und LLM-Antwort", file=sys.stderr)
            
            # Check if the GPT-4 processed text contains V-Test (debug)
            if language == "de" and re.search(r"v[-\s]tests?", processed_text, re.IGNORECASE):
                print(f"‚úì‚úì‚úì DEBUG: Found 'V-Test' or variant in GPT-4 processed text!", file=sys.stderr)
            else:
                print(f"‚ùå‚ùå‚ùå DEBUG: 'V-Test' pattern NOT found in GPT-4 processed text!", file=sys.stderr)
            
            # Apply explicit German word replacements if language is German
            final_text = processed_text
            if language == "de":
                print(f"‚öôÔ∏è Applying explicit German word replacements... (language confirmed as 'de')", file=sys.stderr)
                final_text = self._apply_german_word_replacements(processed_text)
                
                # Check if there was any difference
                if final_text != processed_text:
                    print(f"‚úì Replacements applied successfully", file=sys.stderr)
                else:
                    print(f"‚ÑπÔ∏è No word replacements needed", file=sys.stderr)
                    
                print(f"üîß Text after explicit replacements: '{final_text}'", file=sys.stderr)
                
                # Final check for V-Test (debug)
                if re.search(r"v[-\s]tests?", final_text, re.IGNORECASE):
                    print(f"‚ùå‚ùå‚ùå ERROR: 'V-Test' pattern STILL in final text!", file=sys.stderr)
                else:
                    print(f"‚úì‚úì‚úì SUCCESS: 'V-Test' pattern properly replaced in final text!", file=sys.stderr)
            
            # Log the full processed text
            print(f"Improved transcript: '{final_text}'", file=sys.stderr)
            
            # Add explicit clarification of what mode was used
            if self.llm_optimized:
                print(f"üîç MODUS: GPT-4 mit LLM-OPTIMIERUNG wurde angewendet", file=sys.stderr)
                
                # Zus√§tzliche Info, wenn direkte LLM-Anfrage erkannt wurde
                if "---" in final_text:
                    print(f"ü§ñ Direkte LLM-Anfrage wurde beantwortet", file=sys.stderr)
            else:
                print(f"üîç MODUS: Standard GPT-4 Post-Processing wurde angewendet", file=sys.stderr)
                
            return final_text # Return the text after explicit replacements
        except Exception as e:
            print(f"‚ùå Post-processing error: {str(e)}", file=sys.stderr)
            print(f"‚ùì Error occurred at: {e.__traceback__.tb_lineno}", file=sys.stderr)
            print("‚ö†Ô∏è Returning original transcript instead", file=sys.stderr)
            return transcript
    
    def _get_system_prompt_for_language(self, language):
        """Get appropriate system prompt based on language and optimization mode"""
        # Select the base prompt based on optimization mode
        selected_base_prompt = LLM_OPTIMIZED_BASE_PROMPT if self.llm_optimized else STANDARD_BASE_PROMPT
        
        # Language-specific additions
        if language == "de":
            # Construct the specific correction instructions for German
            correction_instructions = "\nAdditionally, try to correct the following common misrecognitions in German technical context (case-insensitive matching):\n"
            # Use the class attribute here
            for wrong, correct in self.german_word_replacements.items(): 
                # Make case-insensitivity explicit in the instruction to GPT-4
                correction_instructions += f"- If you see '{wrong}' (case-insensitive), try to correct it to '{correct}'.\n"

            # W√§hle die passenden sprachspezifischen Anweisungen f√ºr Deutsch
            german_specific = DE_LLM_OPTIMIZED_ADDITIONS if self.llm_optimized else DE_STANDARD_ADDITIONS
            
            return selected_base_prompt + german_specific + correction_instructions
            
        elif language == "en":
            # W√§hle die passenden sprachspezifischen Anweisungen f√ºr Englisch
            english_specific = EN_LLM_OPTIMIZED_ADDITIONS if self.llm_optimized else EN_STANDARD_ADDITIONS
            
            return selected_base_prompt + english_specific
            
        elif language == "fr":
            # W√§hle die passenden sprachspezifischen Anweisungen f√ºr Franz√∂sisch
            french_specific = FR_LLM_OPTIMIZED_ADDITIONS if self.llm_optimized else FR_STANDARD_ADDITIONS
            
            return selected_base_prompt + french_specific
            
        elif language == "es":
            # W√§hle die passenden sprachspezifischen Anweisungen f√ºr Spanisch
            spanish_specific = ES_LLM_OPTIMIZED_ADDITIONS if self.llm_optimized else ES_STANDARD_ADDITIONS
            
            return selected_base_prompt + spanish_specific
            
        else:
            # F√ºr alle anderen Sprachen verwenden wir generische Anweisungen
            generic_specific = GENERIC_LLM_OPTIMIZED_ADDITIONS if self.llm_optimized else GENERIC_STANDARD_ADDITIONS
            
            return selected_base_prompt + generic_specific
    
    def _apply_german_word_replacements(self, text):
        """Apply explicit, case-insensitive word replacements for German text."""
        if not text:
            return text
        
        print(f"üîç DEBUG: Starting word replacements on text: '{text}'", file=sys.stderr)
        corrected_text = text
        replacement_occurred = False
        
        # Use the class attribute for general replacements
        for wrong, correct in self.german_word_replacements.items():
            # Escape any regex special characters in the 'wrong' string
            escaped_wrong = re.escape(wrong)
            
            # Create patterns with flexibility
            patterns_to_try = []
            
            # Standard pattern with word boundaries
            patterns_to_try.append(r'\b' + escaped_wrong + r'\b')
            
            # Add plural form if not already ending with 's'
            if not wrong.endswith('s'):
                patterns_to_try.append(r'\b' + escaped_wrong + r's\b')
            
            # Add flexibility for hyphens if present
            if '-' in wrong:
                # Replace hyphen with optional hyphen or space pattern
                flexible_pattern = escaped_wrong.replace('\\-', '[-\\s]')
                patterns_to_try.append(r'\b' + flexible_pattern + r'\b')
                # And plural version if needed
                if not wrong.endswith('s'):
                    patterns_to_try.append(r'\b' + flexible_pattern + r's\b')
            
            # Try each pattern
            for pattern in patterns_to_try:
                try:
                    # Check if this pattern has any matches
                    if re.search(pattern, corrected_text, flags=re.IGNORECASE):
                        # Store before replacement for comparison
                        before_replacement = corrected_text
                        
                        # Apply the replacement
                        corrected_text = re.sub(pattern, correct, corrected_text, flags=re.IGNORECASE)
                        
                        # Debug: show exactly what changed, but only if something actually changed
                        if before_replacement != corrected_text:
                            print(f"‚úì Replaced: '{wrong}' ‚Üí '{correct}'", file=sys.stderr)
                            replacement_occurred = True
                except re.error as e:
                    print(f"‚ö†Ô∏è Regex error for pattern '{wrong}': {e}", file=sys.stderr)
        
        # Log summary of replacements
        if replacement_occurred:
            print(f"‚úÖ Completed word replacements", file=sys.stderr)
        else:
            print(f"‚ÑπÔ∏è No word replacements needed", file=sys.stderr)
            
        return corrected_text
    
    @staticmethod
    def get_supported_languages():
        """Return a dictionary of supported languages for UI selection"""
        return {
            "auto": "Auto-detect (Ignore language parameter)",
            "en": "English",
            "de": "Deutsch",
            "fr": "Fran√ßais",
            "es": "Espa√±ol",
            "it": "Italiano",
            "ja": "Êó•Êú¨Ë™û",
            "zh": "‰∏≠Êñá",
            "ru": "–†—É—Å—Å–∫–∏–π",
            "pt": "Portugu√™s",
            "ko": "ÌïúÍµ≠Ïñ¥",
            "ar": "ÿßŸÑÿπÿ±ÿ®Ÿäÿ©",
            "nl": "Nederlands",
            "sv": "Svenska",
            "pl": "Polski"
        } 